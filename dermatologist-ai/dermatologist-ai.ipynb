{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data count: 2000\n",
      "Test data count: 600\n",
      "Valid. data count: 150\n",
      "Classes: {'seborrheic_keratosis': 0, 'nevus': 2, 'melanoma': 1}\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "\n",
    "classes, train_labels, train_files  = data.load_dataset('./data/train')\n",
    "_, test_labels, test_files  = data.load_dataset('./data/test')\n",
    "_, valid_labels, valid_files  = data.load_dataset('./data/valid')\n",
    "\n",
    "print('Train data count: {}'.format(len(train_labels)))\n",
    "print('Test data count: {}'.format(len(test_labels)))\n",
    "print('Valid. data count: {}'.format(len(valid_labels)))\n",
    "print('Classes: {}'.format(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use numeric targets instead of text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'seborrheic_keratosis', 1: 'melanoma', 2: 'nevus'}\n"
     ]
    }
   ],
   "source": [
    "train_targets = [classes[label] for label in train_labels]\n",
    "test_targets = [classes[label] for label in test_labels]\n",
    "valid_targets = [classes[label] for label in valid_labels]\n",
    "\n",
    "target_to_label = {target: label for label, target in classes.items()}\n",
    "print(target_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 Load pretrained Inception v3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models\n",
    "\n",
    "# are we GPU capable?\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "inception_model= torchvision.models.inception_v3(pretrained=True)\n",
    "if use_gpu:\n",
    "    inception_model = inception_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create single image loader\n",
    "For further use we create a image loader from the files. Here we need an image normalizer, so all image pixel values are floats and in a range between -1 and 1.  \n",
    "Next we create a loader that composes several image transformations: resize, center crop, normalization and conversion to PyTorch tensor.  \n",
    "Inception V3 requires the image size of 299. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "imsize = 299\n",
    "\n",
    "# create image normalizer\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# create image transformer\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(imsize),\n",
    "    transforms.CenterCrop(imsize),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "def image_loader(img_path):\n",
    "    '''\n",
    "    Load image from the file and transform it to be consumed by the model\n",
    "    \n",
    "    :param img_path: path to the image file\n",
    "    :return: PyTorch 4D tensor - (1, channels, width, height). CPU or GPU tensor\n",
    "    '''\n",
    "    image = Image.open(img_path)\n",
    "    image = image_transform(image).float()\n",
    "    image = Variable(image, requires_grad=False)\n",
    "    image = image.unsqueeze(0)  # to have 4D tensor\n",
    "    if use_gpu:\n",
    "        image = image.cuda()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict function\n",
    "Now we create a prediction function for the single image. First we load the image and then run prediction on it using inception model.  \n",
    "  \n",
    "**Caution**  \n",
    "Since Inception model uses batch normalization, we must call ```model.eval()``` method to let the model know that we are in prediction mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(img_path):\n",
    "    '''\n",
    "    Predicts an integer labels on the image\n",
    "    \n",
    "    :param img_path: path to the image file\n",
    "    :return: one of the 1000 pretrained labels on the ImageNet data set\n",
    "    '''\n",
    "    image = image_loader(img_path)\n",
    "    inception_model.eval()\n",
    "    outputs = inception_model(image)\n",
    "    _, pred_idx = torch.max(outputs.data, 1)\n",
    "    return pred_idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Data set and its loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin cancer dataset class to provide images and their labels\n",
    "First of all, we define a class to that helps to iterate over the images and their labels. It is a PyTorch specialty, later it is used by the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, image_files, targets, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        assert(len(self.targets) == len(self.image_files))\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_files[idx])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        targets = self.targets[idx]\n",
    "        return [image, targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loader of images and labels\n",
    "Here we create train, validation and test datasets and loaders for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SkinCancerDataset(train_files, train_targets, transform=image_transform)\n",
    "test_ds = SkinCancerDataset(test_files, test_targets, transform=image_transform)\n",
    "valid_ds = SkinCancerDataset(valid_files, valid_targets, transform=image_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the loader\n",
    "Here is a short test of the interplay between data set, data loader and model. Prediction by Inception and targets are not match here, since we have only 3 types of skin cancer, but Inception has 1000 classes as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_targets_tensors(inputs, targets):\n",
    "    '''\n",
    "    Helper function for PyTorch tensor creation\n",
    "    \n",
    "    :param inputs: inputs (such as images)\n",
    "    :param targets: target classes\n",
    "    :return: tuple of inputs and targets PyTorch tensors\n",
    "    '''\n",
    "    inputs = Variable(inputs)\n",
    "    targets = Variable(targets)\n",
    "    if use_gpu:\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 646\n",
      "  78\n",
      " 964\n",
      " 107\n",
      " 314\n",
      " 640\n",
      " 948\n",
      " 769\n",
      " 419\n",
      " 961\n",
      "  78\n",
      " 551\n",
      " 769\n",
      " 798\n",
      "  78\n",
      "  78\n",
      "[torch.cuda.LongTensor of size 16 (GPU 0)]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.LongTensor of size 16 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(iter(test_loader))\n",
    "\n",
    "inputs, targets = get_inputs_targets_tensors(inputs, targets)\n",
    "\n",
    "inception_model.eval()\n",
    "outputs = inception_model(inputs)\n",
    "_, pred_idx = torch.max(outputs.data, 1)\n",
    "\n",
    "print(pred_idx)\n",
    "print(targets.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Modify and train Inception model\n",
    "In order to predict the do breeds only, we need to replace a last fully-connected layer of the Inception model (which predict one of the 1000 categories) with a fully-connected layer for the cancer skin prediction (which has 3 categories). Then we train weights only for this new layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "We need helper functions to prepare and save the checkpoints during the training. It allows us to save the intermediate results and the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "checkpoints_dir = './checkpoints/'\n",
    "best_model_filename = 'model_best.pth.tar'\n",
    "checkpoint_filename = 'checkpoint.pth.tar'\n",
    "\n",
    "def best_model_exists():\n",
    "    '''\n",
    "    Defines whether the file with a best model exists\n",
    "    \n",
    "    :return: True if the best model file exists, False - otherwise\n",
    "    '''\n",
    "    best_model_checkpoint = checkpoints_dir + best_model_filename\n",
    "    return os.path.exists(best_model_checkpoint)\n",
    "\n",
    "def load_saved_best_weights(model):\n",
    "    '''\n",
    "    Loads the saved best weights for the model\n",
    "    \n",
    "    :param model: model to load the weights for\n",
    "    '''\n",
    "    best_model_checkpoint = checkpoints_dir + best_model_filename\n",
    "    model.load_state_dict(torch.load(best_model_checkpoint))\n",
    "\n",
    "def prepare_checkpoints_dir():\n",
    "    '''\n",
    "    Prepares the checkpoints directory - removes old results\n",
    "    '''\n",
    "    if os.path.exists(checkpoints_dir):\n",
    "        shutil.rmtree(checkpoints_dir)\n",
    "    os.makedirs(checkpoints_dir)\n",
    "\n",
    "def save_checkpoint(model, is_best, filename=checkpoint_filename):\n",
    "    '''\n",
    "    Saves checkpoint into the file\n",
    "    \n",
    "    :param model: model to save\n",
    "    :param is_best: True if the model is a best ones, False - otherwise\n",
    "    :param filename: checkpoint file name\n",
    "    '''\n",
    "    filepath = checkpoints_dir + filename\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    if is_best:\n",
    "        best_filepath = checkpoints_dir + best_model_filename\n",
    "        shutil.copyfile(filepath, best_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch train function\n",
    "Train function for a single epoch. It runs the training on the batches of a single epoch. It is called multiple times during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, loader, criterion, optimizer):\n",
    "    '''\n",
    "    Trains the model during the single epoch\n",
    "    \n",
    "    :param model: model to train\n",
    "    :param epoch: epoch number\n",
    "    :param loader: PyTorch data loader\n",
    "    :param criterion: calculates the loss\n",
    "    :param optimizer: model optimizer such as Adam, SGD, etc.\n",
    "    :return: tuple of train loss and accuracy\n",
    "    '''\n",
    "    dataset_size = len(loader.dataset)\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    log_after = 20\n",
    "    batch_counter = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = get_inputs_targets_tensors(inputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # inception model has 2 outputs during the training (returned as tuple):\n",
    "        # predicted class and aux logits. we need here only the first\n",
    "        _, pred_idx = torch.max(outputs[0].data, 1)\n",
    "\n",
    "        loss = criterion(outputs[0], targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_counter % log_after) == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), \n",
    "                dataset_size, loss.data[0]))\n",
    "        running_loss += loss.data[0]\n",
    "        running_correct += torch.sum(pred_idx == targets.data)\n",
    "        batch_counter += 1\n",
    "    \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_correct / dataset_size\n",
    "    \n",
    "    return (epoch_loss, epoch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch test function\n",
    "Test function for a single epoch. It is called multiple times during the training and once during the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, loader):\n",
    "    '''\n",
    "    Tests the model during the single epoch\n",
    "    \n",
    "    :param model: model to test\n",
    "    :param epoch: epoch number\n",
    "    :param loader: PyTorch data loader\n",
    "    :return: tuple of test loss and accuracy\n",
    "    '''\n",
    "    dataset_size = len(loader.dataset)\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    log_after = 10\n",
    "    batch_counter = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = get_inputs_targets_tensors(inputs, targets)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, pred_idx = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        if (batch_counter % log_after) == 0:\n",
    "            print('Test Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), \n",
    "                dataset_size, loss.data[0]))\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        running_correct += torch.sum(pred_idx == targets.data)\n",
    "        batch_counter += 1\n",
    "        \n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_correct / dataset_size\n",
    "    \n",
    "    return (epoch_loss, epoch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function\n",
    "Here is a model train function. We iterate over several epoch and call single epoch train and test for each iteration. Using the test accuracy the function determines the best model, it also saves the checkpoints for each epoch and prints te results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, criterion, optimizer, epochs=10):\n",
    "    '''\n",
    "    Trains the model, saves checkpoints and the best model\n",
    "    \n",
    "    :param model: model to train\n",
    "    :param train_loader: PyTorch train data loader\n",
    "    :param test_loader: PyTorch test data loader\n",
    "    :param criterion: calculates the loss\n",
    "    :param optimizer: model optimizer such as Adam, SGD, etc.\n",
    "    :return: trained model\n",
    "    '''\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1000.0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_epoch_loss, train_epoch_acc = train_epoch(model, epoch, train_loader, criterion, optimizer)\n",
    "        valid_epoch_loss, valid_epoch_acc = test_epoch(model, epoch, valid_loader)\n",
    "            \n",
    "        is_best = False\n",
    "        if valid_epoch_acc > best_acc:\n",
    "            best_acc = valid_epoch_acc\n",
    "            best_loss = valid_epoch_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            is_best = True\n",
    "            \n",
    "        save_checkpoint(model, is_best)\n",
    "        \n",
    "        print('Epoch [{}/{}]\\ttrain loss: {:.4f}\\ttrain acc: {:.4f}\\tvalid loss: {:.4f}\\tvalid acc: {:.4f}'.format(\n",
    "                epoch, epochs,\n",
    "                train_epoch_loss, train_epoch_acc, \n",
    "                valid_epoch_loss, valid_epoch_acc))\n",
    "            \n",
    "    print('Best validation accuracy: {:6f}\\tBest validation loss: {:6f}'.format(best_acc, best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Inception model\n",
    "Here we modify the Inception model for training and prediction of the skin cancer. At the end we create a loss function (Cross Entropy Loss) and use Adam optimizer for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained Inception model\n",
    "inception = torchvision.models.inception_v3(pretrained=True)\n",
    "\n",
    "# freeze all model parameters\n",
    "for param in inception.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# new final layer with 3 classes\n",
    "num_features = inception.fc.in_features\n",
    "inception.fc = torch.nn.Linear(num_features, len(classes))\n",
    "\n",
    "if use_gpu:\n",
    "    inception = inception.cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(inception.fc.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d (3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d (64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d (80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d (192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d (48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d (256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d (48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d (288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d (48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d (288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d (128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d (128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d (128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d (128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d (160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d (160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d (160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d (160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d (160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d (768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d (128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d (192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d (768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d (192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d (1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d (2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d (2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d (2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d (448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d (384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d (2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(inception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the previously saved model or start the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# avoid the PIL error \"OSError: image file is truncated (150 bytes not processed)\"\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "if best_model_exists():\n",
    "    final_model = inception\n",
    "    load_saved_best_weights(final_model)\n",
    "else:\n",
    "    prepare_checkpoints_dir()\n",
    "    final_model = train(inception, train_loader, valid_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to predict skin cancer on the speicified image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_skin_cancer(img_path):\n",
    "    '''\n",
    "    Predicts the skin cancer type on the image\n",
    "    \n",
    "    :param img_path: path to the image file\n",
    "    :return: predicted name of the dog breed\n",
    "    '''\n",
    "    image = image_loader(img_path)\n",
    "    \n",
    "    final_model.eval()\n",
    "    outputs = final_model(image)\n",
    "    _, pred_idx = torch.max(outputs.data, 1)\n",
    "    \n",
    "    return target_to_label[pred_idx[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.661667\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "final_model.eval()\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = get_inputs_targets_tensors(inputs, targets)\n",
    "\n",
    "    outputs = final_model(inputs)\n",
    "    _, pred_idx = torch.max(outputs.data, 1)\n",
    "\n",
    "    correct += torch.sum(pred_idx == targets.data)\n",
    "\n",
    "accuracy = correct / len(test_loader.dataset)\n",
    "print('Test accuracy: {:6f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample prediction CSV, run prediction on the images and save results into a final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Id task_1 task_2\n",
      "0                data/test/melanoma/ISIC_0012258.jpg      0      0\n",
      "1                data/test/melanoma/ISIC_0012356.jpg      0      1\n",
      "2                data/test/melanoma/ISIC_0012369.jpg      1      0\n",
      "3                data/test/melanoma/ISIC_0012395.jpg      0      1\n",
      "4                data/test/melanoma/ISIC_0012425.jpg      0      0\n",
      "5                data/test/melanoma/ISIC_0012758.jpg      0      0\n",
      "6                data/test/melanoma/ISIC_0012989.jpg      0      0\n",
      "7                data/test/melanoma/ISIC_0013072.jpg      1      0\n",
      "8                data/test/melanoma/ISIC_0013073.jpg      1      0\n",
      "9                data/test/melanoma/ISIC_0013242.jpg      1      0\n",
      "10               data/test/melanoma/ISIC_0013277.jpg      0      0\n",
      "11               data/test/melanoma/ISIC_0013321.jpg      0      1\n",
      "12               data/test/melanoma/ISIC_0013374.jpg      1      0\n",
      "13               data/test/melanoma/ISIC_0013411.jpg      1      0\n",
      "14               data/test/melanoma/ISIC_0013414.jpg      0      0\n",
      "15               data/test/melanoma/ISIC_0013455.jpg      0      0\n",
      "16               data/test/melanoma/ISIC_0013457.jpg      1      0\n",
      "17               data/test/melanoma/ISIC_0013459.jpg      0      0\n",
      "18               data/test/melanoma/ISIC_0013472.jpg      0      0\n",
      "19               data/test/melanoma/ISIC_0013473.jpg      1      0\n",
      "20               data/test/melanoma/ISIC_0013565.jpg      0      0\n",
      "21               data/test/melanoma/ISIC_0013577.jpg      1      0\n",
      "22               data/test/melanoma/ISIC_0013588.jpg      1      0\n",
      "23               data/test/melanoma/ISIC_0013615.jpg      1      0\n",
      "24               data/test/melanoma/ISIC_0013617.jpg      0      0\n",
      "25               data/test/melanoma/ISIC_0013636.jpg      1      0\n",
      "26               data/test/melanoma/ISIC_0013678.jpg      1      0\n",
      "27               data/test/melanoma/ISIC_0013696.jpg      0      0\n",
      "28               data/test/melanoma/ISIC_0013733.jpg      0      0\n",
      "29               data/test/melanoma/ISIC_0013739.jpg      0      0\n",
      "..                                               ...    ...    ...\n",
      "570  data/test/seborrheic_keratosis/ISIC_0014386.jpg      0      1\n",
      "571  data/test/seborrheic_keratosis/ISIC_0014392.jpg      0      1\n",
      "572  data/test/seborrheic_keratosis/ISIC_0014409.jpg      0      0\n",
      "573  data/test/seborrheic_keratosis/ISIC_0014419.jpg      1      0\n",
      "574  data/test/seborrheic_keratosis/ISIC_0014457.jpg      0      0\n",
      "575  data/test/seborrheic_keratosis/ISIC_0014474.jpg      0      1\n",
      "576  data/test/seborrheic_keratosis/ISIC_0014500.jpg      1      0\n",
      "577  data/test/seborrheic_keratosis/ISIC_0014503.jpg      0      1\n",
      "578  data/test/seborrheic_keratosis/ISIC_0014567.jpg      0      1\n",
      "579  data/test/seborrheic_keratosis/ISIC_0014574.jpg      0      0\n",
      "580  data/test/seborrheic_keratosis/ISIC_0014575.jpg      0      0\n",
      "581  data/test/seborrheic_keratosis/ISIC_0014586.jpg      0      0\n",
      "582  data/test/seborrheic_keratosis/ISIC_0014587.jpg      0      0\n",
      "583  data/test/seborrheic_keratosis/ISIC_0014588.jpg      0      1\n",
      "584  data/test/seborrheic_keratosis/ISIC_0014590.jpg      0      0\n",
      "585  data/test/seborrheic_keratosis/ISIC_0014600.jpg      1      0\n",
      "586  data/test/seborrheic_keratosis/ISIC_0014619.jpg      1      0\n",
      "587  data/test/seborrheic_keratosis/ISIC_0014626.jpg      0      1\n",
      "588  data/test/seborrheic_keratosis/ISIC_0014627.jpg      0      0\n",
      "589  data/test/seborrheic_keratosis/ISIC_0014629.jpg      0      1\n",
      "590  data/test/seborrheic_keratosis/ISIC_0014631.jpg      0      0\n",
      "591  data/test/seborrheic_keratosis/ISIC_0014634.jpg      0      1\n",
      "592  data/test/seborrheic_keratosis/ISIC_0014643.jpg      0      1\n",
      "593  data/test/seborrheic_keratosis/ISIC_0014644.jpg      1      0\n",
      "594  data/test/seborrheic_keratosis/ISIC_0014645.jpg      1      0\n",
      "595  data/test/seborrheic_keratosis/ISIC_0014647.jpg      0      0\n",
      "596  data/test/seborrheic_keratosis/ISIC_0014648.jpg      0      1\n",
      "597  data/test/seborrheic_keratosis/ISIC_0014649.jpg      0      0\n",
      "598  data/test/seborrheic_keratosis/ISIC_0014652.jpg      1      0\n",
      "599  data/test/seborrheic_keratosis/ISIC_0014653.jpg      1      0\n",
      "\n",
      "[600 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt = pd.read_csv('sample_predictions.csv', index_col=False)\n",
    "dt_res = pd.DataFrame(columns=['Id', 'task_1', 'task_2'])\n",
    "for i, row in dt.iterrows():\n",
    "    res = {}\n",
    "    \n",
    "    pred = predict_skin_cancer(row['Id'])\n",
    "    res['Id'] = row['Id']\n",
    "    \n",
    "    task_1 = 0\n",
    "    if pred == 'melanoma':\n",
    "        task_1 = 1\n",
    "    \n",
    "    task_2 = 0\n",
    "    if pred == 'seborrheic_keratosis':\n",
    "        task_2 = 1\n",
    "        \n",
    "    dt_res.loc[i] = [row['Id'], task_1, task_2]\n",
    "\n",
    "print(dt_res)\n",
    "dt_res.to_csv('final_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
